!pip install numpy
!pip install pandas
!pip install matplotlib
!pip install scikit-learn
!pip install seaborn


	
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
import seaborn as sns


------------------------------------- data --------------------------------------


url="https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/_0eYOqji3unP1tDNKWZMjg/weatherAUS-2.csv"
df = pd.read_csv(url)
df.head()




df.count()



------------------------ pre processing -------------------------------


df = df.dropna()
df.info()

// drop missing value columns



   {{{{{{ issue is : Data leakage considerations
Consider the descriptions above for the columns in the data set. Are there any practical limitations to being able to predict whether it will rain tomorrow given the available data?

so  we adjust our approach and aim to predict today’s rainfall using historical weather data up to and including yesterday, then we can legitimately utilize all of the available features. This shift would be particularly useful for practical applications, such as deciding whether you will bike to work today.
 }}}}}





// renaming columns / shifting data 

df = df.rename(columns={'RainToday': 'RainYesterday',
                        'RainTomorrow': 'RainToday'
                        })




////our next step is a practical one: to simplify the problem and potentially improve accuracy, you'll likely select a single location or a small group of locations with similar weather patterns. This allows you to build a more specialized model that can learn the specific dynamics of that region without the noise from other, dissimilar locations.

  You're questioning the data granularity and a key assumption of the model: that a single model can accurately predict rainfall across all of Australia.

The code you'll likely use will count the number of observations per location. Here's what that step will likely show and what it means:



The three locations—Melbourne, Melbourne Airport, and Watsonia—are all in the same general metropolitan area. By focusing on them, we ensure that the weather data we're using comes from locations that are geographically close and likely to share similar weather patterns. This is much more consistent than building a model that tries to predict rain in both Melbourne and, for example, a distant, arid location like Alice Springs, which would have very different climatic conditions.



df = df[df.Location.isin(['Melbourne','MelbourneAirport','Watsonia',])]
df. info()




///////There may be some variation with Year as well, but we'll leave that out for now. Let's engineer a Season feature from Date and drop Date afterward, since it is most likely less informative than season. An easy way to do this is to define a function that assigns seasons to given months, then use that function to transform the Date column.


def date_to_season(date):
    month = date.month
    if (month == 12) or (month == 1) or (month == 2):
        return 'Summer'
    elif (month == 3) or (month == 4) or (month == 5):
        return 'Autumn'
    elif (month == 6) or (month == 7) or (month == 8):
        return 'Winter'
    elif (month == 9) or (month == 10) or (month == 11):
        return 'Spring'


df['Date'] = pd.to_datetime(df['Date'])

# Apply the function to the 'Date' column
df['Season'] = df['Date'].apply(date_to_season)

# Drop the original 'Date' column
df = df.drop(columns='Date')

df




---------------------------- data extraction --------------------------


X = df.drop(columns='RainToday', axis=1) //  drops rain today and save other all as df in x
y = df['RainToday'] // stores only rain today in y 



// check balance

y.value_counts()

// imbalanced




---------------------- test train ----------------------------

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)


// make transformers

numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()
categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()


# Scale the numeric features
numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])

# One-hot encode the categoricals 
categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])




////handle_unknown='ignore': This is an important parameter. It tells the encoder to ignore any categories it encounters in the test set that it didn't see in the training set, preventing the model from crashing.




// combine in one column

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ])


/// create pipeline

pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(random_state=42))])



// random forest because it is handling imbalances



/// param grid 

param_grid = {
    'classifier__n_estimators': [50, 100],
    'classifier__max_depth': [None, 10, 20],
    'classifier__min_samples_split': [2, 5]
}



//cv

cv = StratifiedKFold(n_splits=5, shuffle=True)




// make GridCV


grid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring='accuracy', verbose=2)
grid_search.fit(X_train, y_train)




---------------------- print accuracy result------------------------------


print("\nBest parameters found: ", grid_search.best_params_)
print("Best cross-validation score: {:.2f}".format(grid_search.best_score_))   // this shows accuracy of training


// print model accuracy score . This score shows your model's accuracy on unseen data.

After all the training, tuning, and cross-validation, the test set score provides the most realistic estimate of how your model will perform in a real-world scenario. It tells you the percentage of correct predictions your model makes on data it has never seen before.

test_score = grid_search.score(X_test, y_test)
print("Test set score: {:.2f}".format(test_score))




----------------------predict ----------------------------------------------


y_pred = grid_search.predict(X_test)


// classification report

print("\nClassification Report:")
print(classification_report(y_test, y_pred))




/// confusion matrix



conf_matrix = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)
disp.plot(cmap='Blues')
plt.title('Confusion Matrix')
plt.show()



//// feature importance



feature_importances = grid_search.best_estimator_['classifier'].feature_importances_

// now combine column names


# Combine numeric and categorical feature names
feature_names = numeric_features + list(grid_search.best_estimator_['preprocessor']
                                        .named_transformers_['cat']
                                        .named_steps['onehot']
                                        .get_feature_names_out(categorical_features))

feature_importances = grid_search.best_estimator_['classifier'].feature_importances_

importance_df = pd.DataFrame({'Feature': feature_names,
                              'Importance': feature_importances
                             }).sort_values(by='Importance', ascending=False)

N = 20  # Change this number to display more or fewer features
top_features = importance_df.head(N)

# Plotting
plt.figure(figsize=(10, 6))
plt.barh(top_features['Feature'], top_features['Importance'], color='skyblue')
plt.gca().invert_yaxis()  # Invert y-axis to show the most important feature on top
plt.title(f'Top {N} Most Important Features in predicting whether it will rain today')
plt.xlabel('Importance Score')
plt.show()




--------------------- try logistic regression -------------------------------------




# Replace RandomForestClassifier with LogisticRegression
pipeline.set_params(classifier=LogisticRegression(random_state=42))

# update the model's estimator to use the new pipeline
grid_search.estimator = pipeline

# Define a new grid with Logistic Regression parameters
param_grid = {
    'classifier__solver': ['liblinear'],
    'classifier__penalty': ['l1', 'l2'],
    'classifier__class_weight': [None, 'balanced']
}

grid_search.param_grid = param_grid

# Fit the updated pipeline with LogisticRegression
grid_search.fit(X_train, y_train)

# Make predictions
y_pred = grid_search.predict(X_test)




// confusin matrix for ths


print(classification_report(y_test, y_pred))

# Generate the confusion matrix 
conf_matrix = confusion_matrix(y_test, y_pred)

plt.figure()
sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d')

# Set the title and labels
plt.title('Rian Classification Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')

# Show the plot
plt.tight_layout()
plt.show()



















